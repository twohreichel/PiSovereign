# PiSovereign Configuration
# ===========================
# Complete configuration reference for all system components

# ====================
# Environment Settings
# ====================
# Application environment: "development" or "production"
# In production, critical security warnings will block startup unless
# PISOVEREIGN_ALLOW_INSECURE_CONFIG=true is set.
environment = "development"

# ====================
# HTTP Server Settings
# ====================
[server]
host = "0.0.0.0"
port = 3000
cors_enabled = true
# Allowed CORS origins (empty = allow all in dev, CRITICAL warning in production)
allowed_origins = []
# Graceful shutdown timeout in seconds
shutdown_timeout_secs = 30
# Log format: "json" for structured JSON logs, "text" for human-readable (default)
log_format = "text"

# ================================
# AI Inference Engine Settings
# ================================
[inference]
# Base URL of the inference server (Ollama/hailo-ollama)
base_url = "http://localhost:11434"
# Default model to use for inference
default_model = "qwen2.5-1.5b-instruct"
# Request timeout in milliseconds
timeout_ms = 60000
# Maximum tokens to generate
max_tokens = 2048
# Temperature for sampling (0.0 - 2.0)
temperature = 0.7
# Top-p (nucleus) sampling
top_p = 0.9
# System prompt (optional)
# system_prompt = "You are a helpful assistant."

# =====================
# Security Settings
# =====================
[security]
# Whitelisted phone numbers for WhatsApp (empty = allow all)
whitelisted_phones = []
# API key for HTTP API authentication (optional, legacy single-key mode)
# api_key = "your-secret-key"

# API key to User ID mapping for multi-user authentication
# Maps API keys to their corresponding user UUIDs
# [security.api_key_users]
# "sk-abc123" = "550e8400-e29b-41d4-a716-446655440000"
# "sk-xyz789" = "6ba7b810-9dad-11d1-80b4-00c04fd430c8"

# Enable rate limiting
rate_limit_enabled = true
# Requests per minute per IP
rate_limit_rpm = 60
# Validate TLS certificates for outbound connections
tls_verify_certs = true
# Connection timeout in seconds for external services
connection_timeout_secs = 30
# Minimum TLS version ("1.2" or "1.3")
min_tls_version = "1.2"

# ==============================
# WhatsApp Business Integration
# ==============================
[whatsapp]
# Meta Graph API access token
# access_token = "your-access-token"
# Phone number ID from WhatsApp Business
# phone_number_id = "your-phone-number-id"
# App secret for webhook signature verification
# app_secret = "your-app-secret"
# Verify token for webhook setup
# verify_token = "your-verify-token"
# Whether webhook signature verification is required
signature_required = true
# Meta Graph API version
api_version = "v18.0"

# =====================
# Database Settings
# =====================
[database]
# Path to the SQLite database file
path = "pisovereign.db"
# Maximum number of connections in the pool
max_connections = 5
# Run migrations on startup
run_migrations = true

# =====================
# Cache Settings
# =====================
[cache]
# Enable caching (disable for debugging)
enabled = true
# Short TTL in seconds (for frequently changing data)
ttl_short_secs = 300  # 5 minutes
# Medium TTL in seconds (for moderately stable data)
ttl_medium_secs = 3600  # 1 hour
# Long TTL in seconds (for stable data)
ttl_long_secs = 86400  # 24 hours
# TTL for dynamic LLM responses (high temperature)
ttl_llm_dynamic_secs = 3600  # 1 hour
# TTL for stable LLM responses (low temperature/factual)
ttl_llm_stable_secs = 86400  # 24 hours
# Maximum entries in L1 (in-memory) cache
l1_max_entries = 10000

# ==============================
# Telemetry / OpenTelemetry
# ==============================
[telemetry]
# Enable OpenTelemetry export
enabled = false
# OTLP endpoint URL (e.g., for Tempo/Jaeger)
otlp_endpoint = "http://localhost:4317"
# Sampling ratio (0.0 to 1.0, where 1.0 = sample all traces)
sample_ratio = 1.0
# Service name for traces
# service_name = "pisovereign"
# Log level filter (e.g., "info", "debug", "pisovereign=debug,tower_http=info")
# log_filter = "pisovereign=info,tower_http=info"
# Batch export timeout in seconds
# export_timeout_secs = 30
# Maximum batch size for trace export
# max_batch_size = 512

# ==============================
# Degraded Mode / Resilience
# ==============================
[degraded_mode]
# Enable degraded mode fallback when backend is unavailable
enabled = true
# Message to return when service is unavailable
unavailable_message = "I'm currently experiencing technical difficulties. Please try again in a moment."
# Cooldown before retrying primary backend (seconds)
retry_cooldown_secs = 30
# Number of failures before entering degraded mode
failure_threshold = 3
# Number of successes required to exit degraded mode
success_threshold = 2

# ==============================
# Retry Configuration (Exponential Backoff)
# ==============================
[retry]
# Initial delay before first retry in milliseconds
initial_delay_ms = 100
# Maximum delay between retries in milliseconds
max_delay_ms = 10000
# Multiplier for exponential backoff (delay = initial * multiplier^attempt)
multiplier = 2.0
# Maximum number of retry attempts
max_retries = 3

# ==============================
# Weather Integration (Open-Meteo)
# ==============================
# [weather]
# Open-Meteo API base URL
# base_url = "https://api.open-meteo.com/v1"
# Connection timeout in seconds
# timeout_secs = 30
# Number of forecast days (1-16)
# forecast_days = 7
# Cache TTL in minutes
# cache_ttl_minutes = 30
# Default location for weather (used when user profile has no location)
# Inline table format: { latitude = 52.52, longitude = 13.405 }
# default_location = { latitude = 52.52, longitude = 13.405 }  # Berlin

# ==============================
# CalDAV Calendar Integration
# ==============================
# [caldav]
# CalDAV server URL (e.g., Baikal, Radicale, Nextcloud)
# server_url = "https://cal.example.com"
# Username for authentication
# username = "your-username"
# Password for authentication
# password = "your-password"
# Default calendar path (optional)
# calendar_path = "/calendars/user/default"
# Verify TLS certificates
# verify_certs = true
# Connection timeout in seconds
# timeout_secs = 30

# ==============================
# Proton Mail Integration
# ==============================
# [proton]
# IMAP server host (Proton Bridge)
# imap_host = "127.0.0.1"
# IMAP server port (default: 1143 for STARTTLS)
# imap_port = 1143
# SMTP server host (Proton Bridge)
# smtp_host = "127.0.0.1"
# SMTP server port (default: 1025 for STARTTLS)
# smtp_port = 1025
# Email address (Bridge account email)
# email = "user@proton.me"
# Bridge password (from Bridge UI, NOT Proton account password)
# password = "bridge-password"
# TLS configuration
# [proton.tls]
# verify_certificates = false  # Omit to verify (secure default), set false for self-signed Bridge certs
# min_tls_version = "1.2"
# ca_cert_path = "/path/to/ca.pem"  # Optional custom CA certificate

# ==============================
# Model Selector (Dynamic Routing)
# ==============================
# [model_selector]
# Model for simple/fast tasks
# small_model = "qwen2.5-1.5b-instruct"
# Model for complex/quality tasks
# large_model = "qwen2.5-7b-instruct"
# Word count threshold to trigger large model
# complexity_word_threshold = 100
# Maximum prompt length (chars) for small model
# small_model_max_prompt_chars = 500
# Keywords that trigger large model usage
# complexity_keywords = ["analyze", "explain", "compare", "summarize", "code", "implement", "debug", "refactor", "translate", "research"]

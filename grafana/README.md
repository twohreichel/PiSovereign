# PiSovereign Monitoring Setup

This directory contains configuration files for monitoring PiSovereign on Raspberry Pi 5.

## Quick Start

### 1. Install Prometheus and Grafana

```bash
# Install Prometheus
sudo apt update
sudo apt install -y prometheus

# Install Grafana
sudo apt install -y software-properties-common
sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
sudo apt update
sudo apt install -y grafana
```

### 2. Configure Prometheus

Copy the Prometheus configuration:

```bash
sudo cp prometheus.yml /etc/prometheus/prometheus.yml
sudo systemctl restart prometheus
```

### 3. Import Grafana Dashboard

1. Open Grafana at `http://<pi-ip>:3000`
2. Default credentials: `admin` / `admin`
3. Add Prometheus as data source:
   - Go to **Configuration** → **Data Sources**
   - Add **Prometheus**
   - URL: `http://localhost:9090`
4. Import the dashboard:
   - Go to **Dashboards** → **Import**
   - Upload `dashboards/pisovereign.json`
   - Select Prometheus data source

## Dashboard Panels

### Overview Row
- **Uptime**: Application uptime in seconds
- **Inference Status**: Hailo-10H NPU health status
- **Total Requests**: Cumulative HTTP requests
- **Active Requests**: Currently processing requests (target: 1-5)
- **Avg Response Time**: Mean response latency
- **Total Tokens**: Total tokens generated by LLM

### HTTP Requests Row
- **Request Rate**: Requests per second over 5-minute window
- **Request Status Distribution**: Success/Client Error/Server Error breakdown

### Inference (Hailo-10H NPU) Row
- **Inference Requests**: Success vs. failed inferences
- **Inference Latency**: Average inference time with thresholds
- **Token Generation Rate**: Tokens per second

### Error Rate & Success Row
- **HTTP Success Rate**: Gauge showing percentage (target: >99%)
- **Inference Success Rate**: Gauge showing percentage (target: >99%)
- **Server Errors**: Count of 5xx errors

## Metrics Endpoint

PiSovereign exposes metrics at:
- JSON format: `GET /metrics`
- Prometheus format: `GET /metrics/prometheus`

### Available Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `app_uptime_seconds` | counter | Application uptime |
| `http_requests_total` | counter | Total HTTP requests |
| `http_requests_success_total` | counter | 2xx responses |
| `http_requests_client_error_total` | counter | 4xx responses |
| `http_requests_server_error_total` | counter | 5xx responses |
| `http_requests_active` | gauge | Currently active requests |
| `http_response_time_avg_ms` | gauge | Average response time |
| `http_response_time_ms_bucket` | histogram | Response time distribution |
| `inference_requests_total` | counter | Total inference requests |
| `inference_requests_success_total` | counter | Successful inferences |
| `inference_requests_failed_total` | counter | Failed inferences |
| `inference_time_avg_ms` | gauge | Average inference latency |
| `inference_time_ms_bucket` | histogram | Inference time distribution |
| `inference_tokens_total` | counter | Total tokens generated |
| `inference_healthy` | gauge | Inference health (0/1) |

### Histogram Buckets

Response time buckets (ms): 5, 10, 25, 50, 100, 250, 500, 1000, 2500, 5000, 10000

Inference time buckets (ms): 100, 250, 500, 1000, 2500, 5000, 10000, 30000, 60000

**Creating histogram panels in Grafana:**

The application exposes histogram data for response time and inference time distributions.
To visualize histograms in Grafana:

1. Use the `/metrics` endpoint which provides `response_time_histogram` and `inference_time_histogram` arrays
2. Each histogram entry contains a bucket upper bound and count
3. Example panel queries:
   - Response time P50/P95/P99 percentiles
   - Inference latency distribution heatmap
   - Per-bucket request count visualization

Note: The histogram data is available via the JSON `/metrics` endpoint and can be visualized
using Grafana's JSON API datasource plugin, or by configuring Prometheus to scrape histogram buckets.

## Alerting Rules

A comprehensive set of Prometheus alerting rules is provided in `alerting_rules.yml`.
Copy to your Prometheus configuration and include in `rule_files`:

```yaml
# /etc/prometheus/prometheus.yml
rule_files:
  - /etc/prometheus/rules/alerting_rules.yml
```

### Included Alerts

| Alert | Severity | Description |
|-------|----------|-------------|
| PiSovereignDown | critical | Application is unreachable |
| InferenceEngineUnhealthy | critical | AI engine unhealthy for >2min |
| HighResponseTime | warning | Avg response time >5s |
| HighInferenceTime | warning | Avg inference time >10s |
| HighErrorRate | warning | Server error rate >5% |
| InferenceFailures | warning | Inference failure rate >10% |
| NoTraffic | info | No requests for >15min |
| HighTokenUsage | info | Token rate >100k/hour |

## Alerts (Quick Start)

Add alert rules to Prometheus for:

```yaml
groups:
  - name: pisovereign
    rules:
      - alert: InferenceUnhealthy
        expr: inference_healthy == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Hailo-10H NPU is unhealthy"
          
      - alert: HighErrorRate
        expr: rate(http_requests_server_error_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High server error rate"
          
      - alert: SlowInference
        expr: inference_time_avg_ms > 5000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Inference latency is high"
```

## Resource Usage on Raspberry Pi 5

The monitoring stack is optimized for Pi's resources:

- **Prometheus**: ~100MB RAM, 15s scrape interval
- **Grafana**: ~150MB RAM
- **Data retention**: 7 days or 1GB (whichever comes first)

Total additional memory: ~250MB

## Docker Compose (Alternative)

For containerized deployment:

```yaml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=7d'
      - '--storage.tsdb.retention.size=1GB'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./dashboards:/etc/grafana/provisioning/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:
```

## Troubleshooting

### Metrics not appearing
1. Check PiSovereign is running: `curl http://localhost:8080/health`
2. Check Prometheus target: `http://localhost:9090/targets`
3. Verify metrics endpoint: `curl http://localhost:8080/metrics/prometheus`

### High memory usage
Reduce Prometheus retention:
```bash
sudo systemctl edit prometheus
# Add: --storage.tsdb.retention.time=3d
```

### Grafana slow
Increase refresh interval in dashboard settings (default: 10s).
